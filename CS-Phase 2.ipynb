{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Ingestion and Cleaning\n",
    "\n",
    "In the Phase 2 of the Case Study, we will carry out the following steps:\n",
    "  - Ingest raw downloaded data\n",
    "  - Output a combined dataset ready for analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function that you'll be using while reading the raw files\n",
    "def is_integer(x):\n",
    "    '''\n",
    "    This function returns True if x is an integer, and False otherwise\n",
    "    '''\n",
    "    try:\n",
    "        return (int(x) == float(x))\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories that contain the files downloaded\n",
    "dir_cs = os.getcwd() + \"/1805_download\" # path to the directory where all the *.csv.zip files are located\n",
    "\n",
    "# Define the output path for the pickle\n",
    "pickle_file =  \"./clean_data.pickle\" # path to save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns we'll be keeping from the dataset\n",
    "cols_to_pick = ['id', 'loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade', 'emp_length',\n",
    "'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status',\n",
    "'purpose', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'open_acc', 'pub_rec',\n",
    "'fico_range_high', 'fico_range_low', 'revol_bal', 'revol_util', 'total_pymnt',\n",
    "'last_pymnt_d', 'recoveries'] # list of features to use for this study as indicated in the handout\n",
    "\n",
    "# Identify the type of each of these column based on your CS-Phase 1 response\n",
    "float_cols = ['loan_amnt', 'funded_amnt', 'installment','annual_inc','dti','delinq_2yrs','open_acc','pub_rec',\n",
    "              'fico_range_high', 'fico_range_low','revol_bal','total_pymnt','recoveries']\n",
    "cat_cols = ['term','grade', 'emp_length','home_ownership','verification_status', 'loan_status', 'purpose', 'earliest_cr_line'] # categorical features\n",
    "perc_cols = ['int_rate', 'revol_util']\n",
    "date_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d']\n",
    "\n",
    "# Ensure that we have types for every column\n",
    "assert set(cols_to_pick) - set(float_cols) - set(cat_cols) - set(perc_cols) - set(date_cols) == set([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the columns selected will not be used directly in the model,\n",
    "# but will be used to generate other features.\n",
    "#\n",
    "# Create variables specifying the features that will be used\n",
    "\n",
    "# All categorical columns other than \"loan_status\" will be used as\n",
    "# discrete features\n",
    "\n",
    "discrete_features = list(set(cat_cols) - set([\"loan_status\"]))\n",
    "\n",
    "# All numeric columns will be used as continuous features\n",
    "continuous_features = list(float_cols + perc_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion\n",
    "Ingest the data files from both sets, perform consistency checks, and prepare one single file for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_files(directory):\n",
    "    '''\n",
    "    This function will ingest every file in the specified directory\n",
    "    into a pandas dataframe. It will return a dictionary containing\n",
    "    these dataframes, keyed by the file name.\n",
    "    \n",
    "    We assume the directory contains files directly downloaded from\n",
    "    the link given in the handout, and *only* those files. Thus, we \n",
    "    assume the files are zipped (pd.read_csv can read zipped files) \n",
    "    and we assume the first line in each file needs to be skipped.\n",
    "    \n",
    "    Note that each file will be read *without* formatting\n",
    "    '''\n",
    "    \n",
    "    # If the directory has no trailing slash, add one\n",
    "    if directory[-1] != \"/\":\n",
    "        directory =  directory + \"/\"\n",
    "    all_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".zip\"):\n",
    "            all_files.append(file)\n",
    "    output = {}\n",
    "    \n",
    "    print(\"Directory \" + directory + \" has \" + str(len(all_files)) + \" files:\")\n",
    "    for i in all_files:\n",
    "        print(\"    Reading file \" + i)\n",
    "        output[i] = pd.read_csv(directory + i, dtype='str', header=1) # read each with dtype='str' and skip_rows =1\n",
    "        \n",
    "        # Some of the files have \"summary\" lines that, for example\n",
    "        # read \"Total number of loans number in Policy 1: .....\"\n",
    "        # To remove those lines, find any lines with non-integer IDs\n",
    "        # and remove them\n",
    "        l = output[i]['id'].tolist()\n",
    "        invalid_rows = [x for x, y in enumerate(l) if not is_integer(y)]# mask rows that have non-integer IDs. Use is_integer method\n",
    "        if len(invalid_rows) != 0:\n",
    "            print(\"Found \" + str(len(invalid_rows)) + \" invalid rows which were removed\")\n",
    "            output[i].drop(output[i].index[invalid_rows])\n",
    "    \n",
    "    return output # return dictionary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /Users/vicky/Documents/GitHub/LendingClubCase/1805_download/ has 12 files:\n",
      "    Reading file LoanStats_securev1_2016Q3.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2016Q2.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats3a_securev1.csv.zip\n",
      "Found 3 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2017Q1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats3d_securev1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2017Q3.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2017Q2.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2016Q1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2016Q4.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats3c_securev1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats_securev1_2017Q4.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file LoanStats3b_securev1.csv.zip\n",
      "Found 2 invalid rows which were removed\n"
     ]
    }
   ],
   "source": [
    "# Ingest the set of files we downloaded using the defined method \"ingest_files\"\n",
    "files_cs = ingest_files(dir_cs) # dictioary of (filename, dataframe) as (key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for key, value in files_cs.items():\n",
    "    li.append(value)\n",
    "data_cs = pd.concat(li, ignore_index=True) # combine \"files_cs\" into a pandas dataframe\n",
    "              # resent index with drop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns of interest from 'data_cs'\n",
    "final_data = data_cs[data_cs.columns[data_cs.columns.isin(cols_to_pick)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 1765451 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting with \" + str(len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typecast the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Remember that we read the data as string (without any formatting). \n",
    "# Now we would typecast the columns based on feature types which you found out in CS Phase 1\n",
    "\n",
    "for i in float_cols:\n",
    "    final_data[i] = final_data[i].astype('float') # typecast float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def clean_perc(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x.strip()[:-1])\n",
    "\n",
    "for i in perc_cols:\n",
    "    final_data[i] = final_data[i].apply(clean_perc) # apply clean_perc to percentage columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def clean_date(x):\n",
    "    if pd.isnull(x):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strptime( x, \"%b-%Y\").date()\n",
    "\n",
    "for i in date_cols:\n",
    "    final_data[i] = final_data[i].apply(clean_date) # typecast date cloumns to datatime using clean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in cat_cols:\n",
    "    final_data[i] = final_data[i].replace(np.nan, None, regex=True)\n",
    "    final_data[i] = final_data[i].replace(r'\\s+', None, regex=True,)# for categorical features if the value is null/empty set it to None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate returns for each loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names of the four returns we'll be calculating as described in Q.6\n",
    "# ret_PESS: Pessimistic return\n",
    "# ret_OPT: Optimistic return\n",
    "# ret_INTa, ret_INTb: Method3 at two differnt values of \"i\"\n",
    "ret_cols = [\"ret_PESS\", \"ret_OPT\", \"ret_INTa\", \"ret_INTb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 6218 rows\n"
     ]
    }
   ],
   "source": [
    "# Remove all rows for loans that were paid back on the days they were issued\n",
    "final_data['loan_length'] = (final_data.last_pymnt_d - final_data.issue_d) / np.timedelta64(1, 'M')\n",
    "n_rows = len(final_data)\n",
    "\n",
    "loan_length_greater_than_0 = final_data['loan_length'] != 0\n",
    "final_data = final_data[loan_length_greater_than_0] # select rows where loan_length is not 0. \n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1-Pessimistic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment',\n",
       "       'grade', 'emp_length', 'home_ownership', 'annual_inc',\n",
       "       'verification_status', 'issue_d', 'loan_status', 'purpose', 'dti',\n",
       "       'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high',\n",
       "       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_pymnt',\n",
       "       'recoveries', 'last_pymnt_d', 'loan_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the return using a simple annualized profit margin\n",
    "# Pessimistic definition (Handout 6a.) (M1)\n",
    "\n",
    "final_data['term_num'] = final_data.term.str.extract('(\\d+)',expand=False).astype(int) # length of loan in months\n",
    "\n",
    "final_data['ret_PESS'] = ((final_data['total_pymnt'] - final_data['funded_amnt']) / \n",
    "                          final_data['funded_amnt']) * (12 / final_data['term_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>loan_length</th>\n",
       "      <th>term_num</th>\n",
       "      <th>ret_PESS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>13720.675783</td>\n",
       "      <td>13705.922743</td>\n",
       "      <td>7.226147</td>\n",
       "      <td>419.678318</td>\n",
       "      <td>87552.821959</td>\n",
       "      <td>15.334059</td>\n",
       "      <td>0.183057</td>\n",
       "      <td>727.115618</td>\n",
       "      <td>731.116134</td>\n",
       "      <td>11.819105</td>\n",
       "      <td>0.104012</td>\n",
       "      <td>17953.620162</td>\n",
       "      <td>39.671009</td>\n",
       "      <td>14416.940089</td>\n",
       "      <td>43.072409</td>\n",
       "      <td>21.552470</td>\n",
       "      <td>36.604167</td>\n",
       "      <td>0.016534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>13099.002608</td>\n",
       "      <td>13087.092031</td>\n",
       "      <td>10.850455</td>\n",
       "      <td>403.002255</td>\n",
       "      <td>75614.074570</td>\n",
       "      <td>17.115259</td>\n",
       "      <td>0.309732</td>\n",
       "      <td>697.185753</td>\n",
       "      <td>701.185835</td>\n",
       "      <td>11.372827</td>\n",
       "      <td>0.209916</td>\n",
       "      <td>15938.189656</td>\n",
       "      <td>51.553367</td>\n",
       "      <td>13715.911024</td>\n",
       "      <td>103.314169</td>\n",
       "      <td>20.614325</td>\n",
       "      <td>38.700331</td>\n",
       "      <td>0.015532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>13994.158359</td>\n",
       "      <td>13986.814639</td>\n",
       "      <td>14.067120</td>\n",
       "      <td>422.951086</td>\n",
       "      <td>72247.026682</td>\n",
       "      <td>18.559948</td>\n",
       "      <td>0.344667</td>\n",
       "      <td>687.684668</td>\n",
       "      <td>691.684703</td>\n",
       "      <td>11.457227</td>\n",
       "      <td>0.242380</td>\n",
       "      <td>15638.311975</td>\n",
       "      <td>55.996011</td>\n",
       "      <td>14190.983843</td>\n",
       "      <td>206.515938</td>\n",
       "      <td>19.037213</td>\n",
       "      <td>42.293356</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>15100.479466</td>\n",
       "      <td>15092.466880</td>\n",
       "      <td>17.529922</td>\n",
       "      <td>464.363825</td>\n",
       "      <td>69926.527940</td>\n",
       "      <td>19.702807</td>\n",
       "      <td>0.358861</td>\n",
       "      <td>682.961538</td>\n",
       "      <td>686.961538</td>\n",
       "      <td>11.509335</td>\n",
       "      <td>0.245029</td>\n",
       "      <td>15349.312189</td>\n",
       "      <td>58.734568</td>\n",
       "      <td>14855.219497</td>\n",
       "      <td>333.777717</td>\n",
       "      <td>18.600838</td>\n",
       "      <td>44.699509</td>\n",
       "      <td>-0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>17692.437972</td>\n",
       "      <td>17667.081249</td>\n",
       "      <td>20.716908</td>\n",
       "      <td>525.910621</td>\n",
       "      <td>72458.833358</td>\n",
       "      <td>20.388148</td>\n",
       "      <td>0.355929</td>\n",
       "      <td>681.687331</td>\n",
       "      <td>685.687331</td>\n",
       "      <td>11.824565</td>\n",
       "      <td>0.239950</td>\n",
       "      <td>16334.950874</td>\n",
       "      <td>59.639968</td>\n",
       "      <td>16751.342627</td>\n",
       "      <td>530.525608</td>\n",
       "      <td>17.768241</td>\n",
       "      <td>50.878259</td>\n",
       "      <td>-0.009972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>19107.094982</td>\n",
       "      <td>19073.208707</td>\n",
       "      <td>24.453986</td>\n",
       "      <td>580.716116</td>\n",
       "      <td>73742.936752</td>\n",
       "      <td>20.502070</td>\n",
       "      <td>0.363597</td>\n",
       "      <td>679.425640</td>\n",
       "      <td>683.425679</td>\n",
       "      <td>11.978212</td>\n",
       "      <td>0.238918</td>\n",
       "      <td>16058.178932</td>\n",
       "      <td>60.549683</td>\n",
       "      <td>17517.538379</td>\n",
       "      <td>722.631428</td>\n",
       "      <td>16.897006</td>\n",
       "      <td>54.440587</td>\n",
       "      <td>-0.015333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>20701.586069</td>\n",
       "      <td>20680.904318</td>\n",
       "      <td>27.082773</td>\n",
       "      <td>654.669567</td>\n",
       "      <td>77288.174763</td>\n",
       "      <td>20.696986</td>\n",
       "      <td>0.379474</td>\n",
       "      <td>677.766193</td>\n",
       "      <td>681.766193</td>\n",
       "      <td>12.231884</td>\n",
       "      <td>0.243567</td>\n",
       "      <td>16806.380804</td>\n",
       "      <td>59.994163</td>\n",
       "      <td>18296.768385</td>\n",
       "      <td>824.464336</td>\n",
       "      <td>14.691292</td>\n",
       "      <td>56.362023</td>\n",
       "      <td>-0.027774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt   funded_amnt   int_rate  installment    annual_inc  \\\n",
       "grade                                                                     \n",
       "A      13720.675783  13705.922743   7.226147   419.678318  87552.821959   \n",
       "B      13099.002608  13087.092031  10.850455   403.002255  75614.074570   \n",
       "C      13994.158359  13986.814639  14.067120   422.951086  72247.026682   \n",
       "D      15100.479466  15092.466880  17.529922   464.363825  69926.527940   \n",
       "E      17692.437972  17667.081249  20.716908   525.910621  72458.833358   \n",
       "F      19107.094982  19073.208707  24.453986   580.716116  73742.936752   \n",
       "G      20701.586069  20680.904318  27.082773   654.669567  77288.174763   \n",
       "\n",
       "             dti  delinq_2yrs  fico_range_low  fico_range_high   open_acc  \\\n",
       "grade                                                                       \n",
       "A      15.334059     0.183057      727.115618       731.116134  11.819105   \n",
       "B      17.115259     0.309732      697.185753       701.185835  11.372827   \n",
       "C      18.559948     0.344667      687.684668       691.684703  11.457227   \n",
       "D      19.702807     0.358861      682.961538       686.961538  11.509335   \n",
       "E      20.388148     0.355929      681.687331       685.687331  11.824565   \n",
       "F      20.502070     0.363597      679.425640       683.425679  11.978212   \n",
       "G      20.696986     0.379474      677.766193       681.766193  12.231884   \n",
       "\n",
       "        pub_rec     revol_bal  revol_util   total_pymnt  recoveries  \\\n",
       "grade                                                                 \n",
       "A      0.104012  17953.620162   39.671009  14416.940089   43.072409   \n",
       "B      0.209916  15938.189656   51.553367  13715.911024  103.314169   \n",
       "C      0.242380  15638.311975   55.996011  14190.983843  206.515938   \n",
       "D      0.245029  15349.312189   58.734568  14855.219497  333.777717   \n",
       "E      0.239950  16334.950874   59.639968  16751.342627  530.525608   \n",
       "F      0.238918  16058.178932   60.549683  17517.538379  722.631428   \n",
       "G      0.243567  16806.380804   59.994163  18296.768385  824.464336   \n",
       "\n",
       "       loan_length   term_num  ret_PESS  \n",
       "grade                                    \n",
       "A        21.552470  36.604167  0.016534  \n",
       "B        20.614325  38.700331  0.015532  \n",
       "C        19.037213  42.293356  0.005764  \n",
       "D        18.600838  44.699509 -0.000147  \n",
       "E        17.768241  50.878259 -0.009972  \n",
       "F        16.897006  54.440587 -0.015333  \n",
       "G        14.691292  56.362023 -0.027774  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria1 = final_data['loan_status'] == 'Fully Paid'\n",
    "criteria2 = final_data['loan_status'] == 'Charged Off'\n",
    "final_data[criteria1 | criteria2].groupby('grade').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2-Optimistic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assuming that if a loan gives a positive return, we can\n",
    "# immediately find a similar loan to invest in; if the loan\n",
    "# takes a loss, we use M1-pessimistic to compute the return\n",
    "\n",
    "final_data['ret_OPT'] = ...\n",
    "\n",
    "final_data.loc[final_data.ret_OPT < 0,'ret_OPT'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ret_method_3(T, i):\n",
    "    '''\n",
    "    Given an investment time horizon (in months) and re-investment\n",
    "    interest rate, calculate the return of each loan\n",
    "    '''\n",
    "    \n",
    "    # Assuming that the total amount paid back was paid at equal\n",
    "    # intervals during the duration of the loan, calculate the\n",
    "    # size of each of these installment\n",
    "    actual_installment = (final_data.total_pymnt - final_data.recoveries) / ...\n",
    "\n",
    "    # Assuming the amount is immediately re-invested at the prime\n",
    "    # rate, find the total amount of money we'll have by the end\n",
    "    # of the loan\n",
    "    cash_by_end_of_loan = actual_installment * ... # compute the quantity given in [] in eq.2.3 of handout\n",
    "    \n",
    "    cash_by_end_of_loan = cash_by_end_of_loan + final_data.recoveries\n",
    "    \n",
    "    # Assuming that cash is then re-invested at the prime rate,\n",
    "    # with monthly re-investment, until T months from the start\n",
    "    # of the loan\n",
    "    remaining_months = T - final_data['loan_length']\n",
    "    final_return = cash_by_end_of_loan * ... \n",
    "\n",
    "    # Find the percentage return\n",
    "    ret_val = (12/T) * ...\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data['ret_INTa'] = ... # call ret_method_3 with T=60, i=0.002\n",
    "final_data['ret_INTb'] = ... # call ret_method_3 with T=60, i=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_float_columns():\n",
    "    '''\n",
    "    This function visualizes Box-and-whisker plots for continuous variables\n",
    "    '''\n",
    "    \n",
    "    # FLoat columns\n",
    "    for i in float_cols + perc_cols + ret_cols:\n",
    "        seaborn.boxplot(final_data[i])\n",
    "\n",
    "        # Print the three highest values\n",
    "        highest_vals = ... # get 3 highest values\n",
    "        \n",
    "        smallest_val = min(final_data[i])\n",
    "        \n",
    "        plt.text(smallest_val, -0.3, highest_vals[0])\n",
    "        plt.text(smallest_val, -0.2, highest_vals[1])\n",
    "        plt.text(smallest_val, -0.1, highest_vals[2])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_cat_columns():\n",
    "    '''\n",
    "    Lists the distinct values for categorical columns\n",
    "    '''\n",
    "    # Categorical columns \n",
    "    for i in cat_cols:\n",
    "        ... # print field name\n",
    "        ... # print number of distinct values\n",
    "        ... # for each distinct value print the number of occurances\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_date_columns():\n",
    "    '''\n",
    "    This function visualizes a timeline density for dates\n",
    "    '''\n",
    "    \n",
    "    # Date columns\n",
    "    for i in date_cols:\n",
    "        final_data[final_data[i].isnull() == False][i].apply(lambda x : str(x.year) +\n",
    "                                                \"-\" + str(x.month)).value_counts(ascending = True).plot()\n",
    "        plt.title(i + \" (\" + str(final_data[i].isnull().sum()) + \" null values)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize continuous features\n",
    "...\n",
    "\n",
    "# visulaize categorical features\n",
    "...\n",
    "\n",
    "# visualize date columns\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are quite a few outliers. \n",
    "# Please identify top-k (decide this based on the visualization) features where outliers are most obvious\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = ... # remove outliers based 1st obvious feature\n",
    "final_data = ... # remove outliers based 2nd obvious feature\n",
    "...\n",
    "final_data = ... # remove outliers based kth obvious feature\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove all loans that are still current\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = ...\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only include loans isssued since 2010\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = ...\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with null values. We allow cateogrical variables to be null\n",
    "# OTHER than grade, which is a particularly important categorical.\n",
    "# All non-categorical variables must be non-null, and we drop\n",
    "# rows that do not meet this requirement\n",
    "\n",
    "required_cols = set(cols_to_pick) - set(cat_cols) - set([\"id\"])\n",
    "required_cols.add(\"grade\")\n",
    "\n",
    "n_rows = len(final_data)\n",
    "\n",
    "... # drop rows that contain null based only on \"required_cols\"\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the data again after cleaning\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the feature correlations\n",
    "... # use sns scatter or pairplot\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize relation between loan status and features\n",
    "... # sns pairplot or scatter plot. Refer to recitations\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe after removing the outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Solution to Q.7 from the handout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the percentage of loans by grade, the default by grade,\n",
    "# and the return of each grade\n",
    "perc_by_grade = (final_data.grade.value_counts()*100/len(final_data)).sort_index()\n",
    "\n",
    "default_by_grade = final_data.groupby(\"grade\").apply(lambda x : (x.loan_status != \"Fully Paid\").sum()*100/len(x) )\n",
    "ret_by_grade_OPT = ... # average return for M2-Optimistic for each loan grade\n",
    "ret_by_grade_PESS = ... # average return for M1-Pessimistic for each loan grade\n",
    "ret_by_grade_INTa = ... # average return for M3\n",
    "ret_by_grade_INTb = ... # average return for M3\n",
    "int_rate_by_grade = ... # average interest rate for each grade\n",
    "\n",
    "combined = pd.DataFrame(perc_by_grade)\n",
    "combined.columns = ['perc_of_loans']\n",
    "combined['perc_default'] = default_by_grade\n",
    "combined['avg_int_rate'] = int_rate_by_grade\n",
    "combined['return_OPT'] = ret_by_grade_OPT\n",
    "combined['return_PESS'] = ret_by_grade_PESS\n",
    "combined['return_INTa'] = ret_by_grade_INTa\n",
    "combined['return_INTb'] = ret_by_grade_INTb\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output of previous cell, write down your answers to Q.7 from the handout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the \"total_pymnt\" and \"recoveries\" from the list of continuous features\n",
    "continuous_features = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we remove `total_pymt` and `recoveries` from the data for the task of predicting whether to give loan or not, although these are highly predictive features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the prepared data for modeling in next Phase.\n",
    "pickle.dump( [final_data, discrete_features, continuous_features, ret_cols], open(pickle_file, \"wb\") )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
